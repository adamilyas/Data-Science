{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "Applications of NLP\n",
    "1. Spam detection\n",
    "2. Part-Of-Speech taggin \n",
    "3. Named Entity Recognition\n",
    "4. Sentiment Analysis\n",
    "5. Machine Translation (Google translate)\n",
    "6. Information Extraction\n",
    "\n",
    "Spam detection using various NLP methods in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your command line/ terminal,\n",
    "```\n",
    "pip install nltk\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From nltk download shell, download the *stopwords corpus* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download_shell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download *SMS Spam Collection Data Set* from the following link:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/sms+spam+collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\\n'\n"
     ]
    }
   ],
   "source": [
    "# just testing to see the format of file\n",
    "\n",
    "with open(\"data/SMSSpamCollection\", \"rb\") as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the line, we can observe the format of the file,\n",
    "\n",
    "Columns are seperated with a tab \"\\t\" and \"\\n\" refers to a line break (a new row)\n",
    "\n",
    "Lets create a dateframe from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df = pd.read_csv(\"data/SMSSpamCollection\", sep=\"\\t\", header=None, names=[\"label\", \"message\"])\n",
    "sms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 message\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels from string to binary\n",
    "- 0: not spam\n",
    "- 1: spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df[\"label\"] = sms_df[\"label\"].apply(lambda x: 1 if x==\"spam\" else 0)\n",
    "sms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "0        4825   4516                             Sorry, I'll call later   30\n",
       "1         747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df.groupby(\"label\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the length of a message (characters) to a new column *len_char*, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>len_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  len_char\n",
       "0      0  Go until jurong point, crazy.. Available only ...       111\n",
       "1      0                      Ok lar... Joking wif u oni...        29\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...       155\n",
       "3      0  U dun say so early hor... U c already then say...        49\n",
       "4      0  Nah I don't think he goes to usf, he lives aro...        61"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df[\"len_char\"] = sms_df[\"message\"].apply(len)\n",
    "sms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that histogram usually graphs out the counts of the item against the item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Character Length')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x285ea189160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot()\n",
    "sms_df[\"len_char\"].plot.hist(bins=200)\n",
    "plt.xlabel(\"Character Length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a bimodal behavior, where there are 2 peaks\n",
    "\n",
    "Now lets investigate messages with length over 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>len_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>0</td>\n",
       "      <td>For me the love should start with attraction.i...</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>0</td>\n",
       "      <td>The last thing i ever wanted to do was hurt yo...</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>0</td>\n",
       "      <td>Indians r poor but India is not a poor country...</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>0</td>\n",
       "      <td>How to Make a girl Happy? It's not at all diff...</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>0</td>\n",
       "      <td>Sad story of a Man - Last week was my b'day. M...</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>0</td>\n",
       "      <td>Sad story of a Man - Last week was my b'day. M...</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>0</td>\n",
       "      <td>Good evening Sir, hope you are having a nice d...</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>0</td>\n",
       "      <td>&amp;lt;#&amp;gt;  is fast approaching. So, Wish u a v...</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>0</td>\n",
       "      <td>Hey sweet, I was wondering when you had a mome...</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>0</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>0</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>0</td>\n",
       "      <td>Solve d Case : A Man Was Found Murdered On  &amp;l...</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280</th>\n",
       "      <td>0</td>\n",
       "      <td>Solve d Case : A Man Was Found Murdered On  &amp;l...</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>0</td>\n",
       "      <td>Solve d Case : A Man Was Found Murdered On  &amp;l...</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0</td>\n",
       "      <td>I can't keep going through this. It was never ...</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>0</td>\n",
       "      <td>no, i *didn't* mean to post it. I wrote it, an...</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>0</td>\n",
       "      <td>Can you tell Shola to please go to college of ...</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            message  len_char\n",
       "1085      0  For me the love should start with attraction.i...       910\n",
       "1863      0  The last thing i ever wanted to do was hurt yo...       790\n",
       "2434      0  Indians r poor but India is not a poor country...       629\n",
       "1579      0  How to Make a girl Happy? It's not at all diff...       611\n",
       "2158      0  Sad story of a Man - Last week was my b'day. M...       588\n",
       "2849      0  Sad story of a Man - Last week was my b'day. M...       588\n",
       "2380      0  Good evening Sir, hope you are having a nice d...       482\n",
       "3017      0  &lt;#&gt;  is fast approaching. So, Wish u a v...       461\n",
       "1513      0  Hey sweet, I was wondering when you had a mome...       458\n",
       "5104      0  A Boy loved a gal. He propsd bt she didnt mind...       446\n",
       "2370      0  A Boy loved a gal. He propsd bt she didnt mind...       446\n",
       "2681      0  Solve d Case : A Man Was Found Murdered On  &l...       444\n",
       "3280      0  Solve d Case : A Man Was Found Murdered On  &l...       444\n",
       "2408      0  Solve d Case : A Man Was Found Murdered On  &l...       444\n",
       "2010      0  I can't keep going through this. It was never ...       431\n",
       "4905      0  no, i *didn't* mean to post it. I wrote it, an...       415\n",
       "4399      0  Can you tell Shola to please go to college of ...       408"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df[sms_df[\"len_char\"] > 400].sort_values(\"len_char\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df.iloc[1085][\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x00000285EA4505C0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x00000285EA594A20>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x285ea3925c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sms_df.hist(column=\"len_char\", by=\"label\", bins=100, figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*not spam vs spam*\n",
    "FREQUENCY AGAINST CHARACTER LENGTH\n",
    "\n",
    "0: not spam. the mean message length (char) for 0 (not spam) is around 50\n",
    "\n",
    "1: spam. The mean message length (char) for 1 (spam) is around 170\n",
    "\n",
    "*We can observe that spam messages have more characters in their messages*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words (Text Pre-processing method)\n",
    "\n",
    "## Aim: Convert a sequence of words to a vector of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords # we downloaded earlier\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords contains very commons words are probably not going to be very helpful in help in our spam detection.\n",
    "\n",
    "We can use stopwords from the nltk corpus to remove common words from our messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_punct(sentence):\n",
    "    \"\"\"\n",
    "    1. Remove Punctuation\n",
    "    2. Remove stopwords\n",
    "    \n",
    "    Returns\n",
    "        A list of words without stopswords and punctuation\n",
    "    \"\"\"\n",
    "    no_punct = \"\".join([char for char in sentence if char not in string.punctuation])\n",
    "    # check if characters are punctuation, join back into a string and check if words are stopwords\n",
    "    \n",
    "    return [word for word in no_punct.split() if word not in stopwords.words(\"english\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'name', 'adam']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords_punct(\"hello there my name is: adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>len_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  len_char\n",
       "0      0  Go until jurong point, crazy.. Available only ...       111\n",
       "1      0                      Ok lar... Joking wif u oni...        29\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...       155\n",
       "3      0  U dun say so early hor... U c already then say...        49\n",
       "4      0  Nah I don't think he goes to usf, he lives aro...        61"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_df[\"clean_message\"] = sms_df[\"message\"].apply(remove_stopwords_punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "Refers to the normalization of words, by reducing them to their root word ie. having: gaming -> game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>len_char</th>\n",
       "      <th>clean_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>147</td>\n",
       "      <td>[FreeMsg, Hey, darling, 3, weeks, word, back, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>77</td>\n",
       "      <td>[Even, brother, like, speak, They, treat, like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>160</td>\n",
       "      <td>[As, per, request, Melle, Melle, Oru, Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>157</td>\n",
       "      <td>[WINNER, As, valued, network, customer, select...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>154</td>\n",
       "      <td>[Had, mobile, 11, months, U, R, entitled, Upda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  len_char  \\\n",
       "0      0  Go until jurong point, crazy.. Available only ...       111   \n",
       "1      0                      Ok lar... Joking wif u oni...        29   \n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...       155   \n",
       "3      0  U dun say so early hor... U c already then say...        49   \n",
       "4      0  Nah I don't think he goes to usf, he lives aro...        61   \n",
       "5      1  FreeMsg Hey there darling it's been 3 week's n...       147   \n",
       "6      0  Even my brother is not like to speak with me. ...        77   \n",
       "7      0  As per your request 'Melle Melle (Oru Minnamin...       160   \n",
       "8      1  WINNER!! As a valued network customer you have...       157   \n",
       "9      1  Had your mobile 11 months or more? U R entitle...       154   \n",
       "\n",
       "                                       clean_message  \n",
       "0  [Go, jurong, point, crazy, Available, bugis, n...  \n",
       "1                     [Ok, lar, Joking, wif, u, oni]  \n",
       "2  [Free, entry, 2, wkly, comp, win, FA, Cup, fin...  \n",
       "3      [U, dun, say, early, hor, U, c, already, say]  \n",
       "4  [Nah, I, dont, think, goes, usf, lives, around...  \n",
       "5  [FreeMsg, Hey, darling, 3, weeks, word, back, ...  \n",
       "6  [Even, brother, like, speak, They, treat, like...  \n",
       "7  [As, per, request, Melle, Melle, Oru, Minnamin...  \n",
       "8  [WINNER, As, valued, network, customer, select...  \n",
       "9  [Had, mobile, 11, months, U, R, entitled, Upda...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_df[\"stem_message\"] = sms_df[\"clean_message\"].apply(lambda x: [ps.stem(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>len_char</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>stem_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "      <td>[Go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, FA, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "      <td>[U, dun, say, earli, hor, U, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
       "      <td>[nah, I, dont, think, goe, usf, live, around, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  len_char  \\\n",
       "0      0  Go until jurong point, crazy.. Available only ...       111   \n",
       "1      0                      Ok lar... Joking wif u oni...        29   \n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...       155   \n",
       "3      0  U dun say so early hor... U c already then say...        49   \n",
       "4      0  Nah I don't think he goes to usf, he lives aro...        61   \n",
       "\n",
       "                                       clean_message  \\\n",
       "0  [Go, jurong, point, crazy, Available, bugis, n...   \n",
       "1                     [Ok, lar, Joking, wif, u, oni]   \n",
       "2  [Free, entry, 2, wkly, comp, win, FA, Cup, fin...   \n",
       "3      [U, dun, say, early, hor, U, c, already, say]   \n",
       "4  [Nah, I, dont, think, goes, usf, lives, around...   \n",
       "\n",
       "                                        stem_message  \n",
       "0  [Go, jurong, point, crazi, avail, bugi, n, gre...  \n",
       "1                       [Ok, lar, joke, wif, u, oni]  \n",
       "2  [free, entri, 2, wkli, comp, win, FA, cup, fin...  \n",
       "3      [U, dun, say, earli, hor, U, c, alreadi, say]  \n",
       "4  [nah, I, dont, think, goe, usf, live, around, ...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization using SKLEARN\n",
    "\n",
    "Using the bag of words model, we:\n",
    "\n",
    "1. Term Frequency: Count the frequency of a word in each message\n",
    "2. Inverse document frequency: Weighing of counts,  more frequent tokens get lower weight\n",
    "3. normalize the vector to a unit length, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each vector will have as many dimensions as there are unique words in the sms corpus\n",
    "\n",
    "<table border = 1>\n",
    "<tr>\n",
    "<th></th> <th>Message 1</th> <th>Message 2</th> <th>...</th> <th>Message N</th> \n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 1 Count</b></td><td>0</td><td>1</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 2 Count</b></td><td>0</td><td>0</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>...</b></td> <td>1</td><td>2</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word N Count</b></td> <td>0</td><td>1</td><td>...</td><td>1</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column will represent a message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.stem.porter import PorterStemmer\n",
    "#from nltk.corpus import stopwords\n",
    "#import string\n",
    "\n",
    "def clean_text(sentence):\n",
    "    \"\"\"\n",
    "    1. Remove Punctuation\n",
    "    2. Remove stopwords\n",
    "    \n",
    "    Returns\n",
    "        A list of words without stopswords and punctuation\n",
    "    \"\"\"\n",
    "    \n",
    "    no_punct = \"\".join([char for char in sentence if char not in string.punctuation])\n",
    "    # check if characters are punctuation, join back into a string and check if words are stopwords\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    # stem each word into its root word\n",
    "    return [ps.stem(word) for word in no_punct.split() if word not in stopwords.words(\"english\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=clean_text).fit(sms_df[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8424"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_transformer.vocabulary_) # around 8000 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U dun say so early hor... U c already then say...'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4 = sms_df.iloc[3][\"message\"]\n",
    "m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1080)\t2\n",
      "  (0, 1303)\t1\n",
      "  (0, 1976)\t1\n",
      "  (0, 2867)\t1\n",
      "  (0, 2885)\t1\n",
      "  (0, 3905)\t1\n",
      "  (0, 6417)\t2\n"
     ]
    }
   ],
   "source": [
    "bow4 = bow_transformer.transform([m4])\n",
    "print(bow4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8424)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7 unique words in message 4\n",
    "\n",
    "LHS refer to the word, and RHS shows the frequency in the message\n",
    "\n",
    "To get the words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U\n",
      "alreadi\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "for i in [1080, 1303, 1976]:\n",
    "    print(bow_transformer.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead of only one message, we apply the bow transform to all the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = bow_transformer.transform(sms_df[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sparse matrix:  (5572, 8424)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of sparse matrix: \", bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55398"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.nnz # non zero messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.11802244842445847\n"
     ]
    }
   ],
   "source": [
    "sparsity = (100.0 * bow.nnz / (bow.shape[0] * bow.shape[1]))\n",
    "print('sparsity: {}'.format(sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the transformed bag of words into the tf-idf transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf4 = tfidf_transformer.transform(bow4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1080)\t2\n",
      "  (0, 1303)\t1\n",
      "  (0, 1976)\t1\n",
      "  (0, 2867)\t1\n",
      "  (0, 2885)\t1\n",
      "  (0, 3905)\t1\n",
      "  (0, 6417)\t2 \n",
      "\n",
      "  (0, 6417)\t0.5030951390075489\n",
      "  (0, 3905)\t0.45224890015988634\n",
      "  (0, 2885)\t0.32670422477536987\n",
      "  (0, 2867)\t0.30095444104414726\n",
      "  (0, 1976)\t0.3063162561599612\n",
      "  (0, 1303)\t0.27245285137643094\n",
      "  (0, 1080)\t0.42070985528018606\n"
     ]
    }
   ],
   "source": [
    "print(bow4, \"\\n\") # count vectorize\n",
    "print(tf4) # idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_tfidf = tfidf_transformer.transform(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model\n",
    "\n",
    "Naive Bayes classifier algorithm is a good choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.inf.ed.ac.uk/teaching/courses/inf2b/learnnotes/inf2b-learn-note07-2up.pdf\n",
    "\n",
    "https://en.wikipedia.org/wiki/Naive_Bayes_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_detect_model = MultinomialNB().fit(message_tfidf, sms_df[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Example on 1 message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label                                                            0\n",
      "message          U dun say so early hor... U c already then say...\n",
      "len_char                                                        49\n",
      "clean_message        [U, dun, say, early, hor, U, c, already, say]\n",
      "stem_message         [U, dun, say, earli, hor, U, c, alreadi, say]\n",
      "Name: 3, dtype: object \n",
      "\n",
      "U dun say so early hor... U c already then say... \n",
      "\n",
      "  (0, 1080)\t2\n",
      "  (0, 1303)\t1\n",
      "  (0, 1976)\t1\n",
      "  (0, 2867)\t1\n",
      "  (0, 2885)\t1\n",
      "  (0, 3905)\t1\n",
      "  (0, 6417)\t2 \n",
      "\n",
      "  (0, 6417)\t0.5030951390075489\n",
      "  (0, 3905)\t0.45224890015988634\n",
      "  (0, 2885)\t0.32670422477536987\n",
      "  (0, 2867)\t0.30095444104414726\n",
      "  (0, 1976)\t0.3063162561599612\n",
      "  (0, 1303)\t0.27245285137643094\n",
      "  (0, 1080)\t0.42070985528018606\n"
     ]
    }
   ],
   "source": [
    "print(sms_df.iloc[3], \"\\n\")\n",
    "print(m4,\"\\n\")\n",
    "print(bow4,\"\\n\")\n",
    "print(tf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_detect_model.predict(tf4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on all messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = spam_detect_model.predict(message_tfidf) # all tf-idf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_df[\"prediction\"] = all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = sms_df.drop([\"clean_message\", \"stem_message\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>len_char</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  len_char  \\\n",
       "0      0  Go until jurong point, crazy.. Available only ...       111   \n",
       "1      0                      Ok lar... Joking wif u oni...        29   \n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...       155   \n",
       "3      0  U dun say so early hor... U c already then say...        49   \n",
       "4      0  Nah I don't think he goes to usf, he lives aro...        61   \n",
       "\n",
       "   prediction  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(sms_df[\"message\"], sms_df[\"label\"], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.stem.porter import PorterStemmer\n",
    "#from nltk.corpus import stopwords\n",
    "#import string\n",
    "\n",
    "def clean_text(sentence):\n",
    "    \"\"\"\n",
    "    1. Remove Punctuation\n",
    "    2. Remove stopwords\n",
    "    \n",
    "    Returns\n",
    "        A list of words without stopswords and punctuation\n",
    "    \"\"\"\n",
    "    \n",
    "    no_punct = \"\".join([char for char in sentence if char not in string.punctuation])\n",
    "    # check if characters are punctuation, join back into a string and check if words are stopwords\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    # stem each word into its root word\n",
    "    return [ps.stem(word) for word in no_punct.split() if word not in stopwords.words(\"english\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=clean_text)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will use sklearn pipeline\n",
    "To store a pipeline of workflows, this allows us to set up all the transformation that we will do to the data for future use\n",
    "\n",
    "Pipeline can be used to chain multiple estimators into one\n",
    "\n",
    "Note that: all the estimators in the pipeline except the last one, must be transformers (have the transform method). The last estimator may be any type (transformers, estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function clean_text at 0x00000285E68D20D0>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(msg_train, label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can directly pass data into the pipeline and the pre processing will be done along side the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9581339712918661\n",
      "Error rate:  0.041866028708133975\n"
     ]
    }
   ],
   "source": [
    "accuracy_rate = (predictions == label_test).mean()\n",
    "print(\"Accuracy: \", accuracy_rate)\n",
    "error_rate = (predictions != label_test).mean()\n",
    "print(\"Error rate: \", error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>len_char</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  len_char  \\\n",
       "0      0  Go until jurong point, crazy.. Available only ...       111   \n",
       "1      0                      Ok lar... Joking wif u oni...        29   \n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...       155   \n",
       "3      0  U dun say so early hor... U c already then say...        49   \n",
       "4      0  Nah I don't think he goes to usf, he lives aro...        61   \n",
       "\n",
       "   prediction  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = sms_df.drop([\"clean_message\",\"stem_message\"], axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"prediction\"] = pipeline.predict(final_df[\"message\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_pred = final_df[final_df[\"label\"] != final_df[\"prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      1445\n",
      "          1       1.00      0.69      0.82       227\n",
      "\n",
      "avg / total       0.96      0.96      0.95      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using other models: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=clean_text)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function clean_text at 0x00000285E68D20D0>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_pipeline.fit(msg_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_predictions = forest_pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      1445\n",
      "          1       0.99      0.78      0.87       227\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test, forest_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using other models: Ada Boost Classifier https://towardsdatascience.com/boosting-algorithm-adaboost-b6737a9ee60c\n",
    "\n",
    "Adaptive Boosting http://scikit-learn.org/stable/modules/ensemble.html\n",
    "\n",
    "The core principles of AdaBoost is to fit a sequence of weaklearners (models that are only slightly better than random guessing, such as small decision trees) on a repeatedly modified versions of the data.\n",
    "\n",
    "The predictions from all of them are combined through a weighted majority vote (sum) to produce the final prediction.\n",
    "\n",
    "Each so-called boosting iteration consist of applying weights $w_1, w_2, , w_N$ to each of the training samples.\n",
    "\n",
    "Initially, $w_i = 1/N$ for all i, so that the first step simply trains a weak learner on the original data\n",
    "\n",
    "For each successive iteration, the sample weights are individually modified and the learning algorithm is reapplied to the reweighted data.\n",
    "\n",
    "At a given step, those training examples that were incorrectly predicted by the boosted model induced at the previous step have their weights increased, whereas the weights are decreased for those that were predicted correctly.\n",
    "\n",
    "As iterations proceed, examples that are difficult to predict receive ever-increasing influence. Each subsequent weak learner is thereby forced to concentrate on the examples that are missed by the previous ones in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=clean_text)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', AdaBoostClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function clean_text at 0x00000285E68D20D0>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=...m='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None))])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_boost_pipeline.fit(msg_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pred =  ada_boost_pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      1445\n",
      "          1       0.91      0.80      0.85       227\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test, ada_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:  0.9688995215311005\n",
      "Ada Boost Classifier Accurary:  0.9623205741626795\n"
     ]
    }
   ],
   "source": [
    "#compare\n",
    "import numpy as np\n",
    "forest_accuracy = np.mean(forest_predictions == label_test)\n",
    "print(\"Random Forest: \", forest_accuracy)\n",
    "ada_accuracy = np.mean(ada_pred == label_test)\n",
    "print(\"Ada Boost Classifier Accurary: \", ada_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
